{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 공식 문서의 import code ===========================================================================\n",
    "#\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "from keras.models import load_model\n",
    "#\n",
    "# =================================================================================================\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "# 파라미터 조정하는 부분 ================================================================================\n",
    "#\n",
    "\n",
    "batch_size = 100\n",
    "num_classes = 576\n",
    "epochs = 12\n",
    "basePoint = [126.916810,37.548029]\n",
    "squareSize=0.011\n",
    "\n",
    "img_rows, img_cols = 24, 24\n",
    "\n",
    "input_shape=(24,24,1)\n",
    "\n",
    "#train :  test = r_train :  r_test 개수 비율\n",
    "r_train=5\n",
    "r_test=1\n",
    "\n",
    "pNum=10\n",
    "\n",
    "#\n",
    "# ==================================================================================================\n",
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 학습 할 json 파일 열기 ===============================================================================\n",
    "#\n",
    "\n",
    "with open(\"./data/trainData.json\",\"r\") as js:\n",
    "    jsonData=json.load(js)\n",
    "\n",
    "#\n",
    "# ==================================================================================================\n",
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# json 파일을 이용해 x_train,y_train 만드는 함수==========================================================\n",
    "#\n",
    "def MakeTrainSet(jsonData):\n",
    "    \n",
    "    x_train=list()\n",
    "    y_train=list()\n",
    "    \n",
    "    # 24*24 중 1개의 타일 변의 크기\n",
    "    dl = squareSize / img_rows\n",
    "\n",
    "    # basePoint 사각형 내에 있는 데이터만 거르기\n",
    "    verifyJsonData=list()\n",
    "    for x in jsonData:\n",
    "        if basePoint[0]<= float(x['longitude']) <basePoint[0]+squareSize:\n",
    "            if basePoint[1] <= float(x['latitude']) < basePoint[1]+squareSize:\n",
    "                verifyJsonData.append(x)\n",
    "\n",
    "    # 검증된 데이터셋을 [x좌표,y좌표,번호] 형식으로 만들기\n",
    "    locationSet=list()\n",
    "    for x in verifyJsonData:\n",
    "        idx,idy=0,0\n",
    "        for _idx in range(1,img_rows+1):\n",
    "            if basePoint[0]+_idx*dl > float(x['longitude']):\n",
    "                idx = _idx-1\n",
    "                break\n",
    "        for _idy in range(1,img_rows+1):\n",
    "            if basePoint[1]+_idy*dl > float(x['latitude']):\n",
    "                idy = _idy-1\n",
    "                break\n",
    "        locationSet.append([idx,idy,idx+img_rows*idy])\n",
    "\n",
    "    # pNum의 개수만큼 점의 개수를 가지는 이미지를 x_train로 만들고 y_train으로 정답번호 주기\n",
    "    tmpmap = [ [0 for _ in range(img_rows)] for _ in range(img_rows)]\n",
    "    for i in range(pNum):\n",
    "        tmpmap[locationSet[i][0]][locationSet[i][1]]+=1\n",
    "    for i in range(pNum+1,len(locationSet)):\n",
    "        x_train.append(copy.deepcopy(tmpmap))\n",
    "        y_train.append(locationSet[i][2])\n",
    "        tmpmap[locationSet[i][0]][locationSet[i][1]]+=1\n",
    "        tmpmap[locationSet[i-pNum+1][0]][locationSet[i-pNum+1][1]]-=1\n",
    "        \n",
    "        \n",
    "    # np array 로 만들기\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # train : test = r_train : r_test\n",
    "    line1 = (x_train.shape[0]//(r_train+r_test))*r_train\n",
    "\n",
    "    x_test = x_train[line1:]\n",
    "    x_train = x_train[0:line1]\n",
    "\n",
    "    y_test = y_train[line1:]\n",
    "    y_train = y_train[0:line1]\n",
    "    \n",
    "    #혹시 케라스 이미지 포멧이 채널이 first인경우는 바꿔준다\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "        \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= pNum\n",
    "    x_test /= pNum\n",
    "    \n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return x_train,x_test,y_train,y_test\n",
    "    \n",
    "#\n",
    "# ==================================================================================================\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 데이터 전처리 하는 code 및 일부 데이터 확인 ===============================================================\n",
    "#\n",
    "\n",
    "x_train,x_test,y_train,y_test = MakeTrainSet(jsonData)\n",
    "\n",
    "#\n",
    "# ==================================================================================================\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21060 samples, validate on 4215 samples\n",
      "Epoch 1/12\n",
      "21060/21060 [==============================] - 11s 521us/step - loss: 3.2218 - acc: 0.3028 - val_loss: 2.6730 - val_acc: 0.3770\n",
      "Epoch 2/12\n",
      "21060/21060 [==============================] - 10s 484us/step - loss: 1.9200 - acc: 0.4501 - val_loss: 2.1908 - val_acc: 0.4052\n",
      "Epoch 3/12\n",
      "21060/21060 [==============================] - 10s 492us/step - loss: 1.7414 - acc: 0.4715 - val_loss: 1.9822 - val_acc: 0.4365\n",
      "Epoch 4/12\n",
      "21060/21060 [==============================] - 10s 488us/step - loss: 1.6609 - acc: 0.4813 - val_loss: 2.0282 - val_acc: 0.4482\n",
      "Epoch 5/12\n",
      "21060/21060 [==============================] - 10s 483us/step - loss: 1.6192 - acc: 0.4888 - val_loss: 1.9986 - val_acc: 0.4550\n",
      "Epoch 6/12\n",
      "21060/21060 [==============================] - 10s 466us/step - loss: 1.5869 - acc: 0.4914 - val_loss: 2.0374 - val_acc: 0.3924\n",
      "Epoch 7/12\n",
      "21060/21060 [==============================] - 9s 430us/step - loss: 1.5648 - acc: 0.4943 - val_loss: 1.9450 - val_acc: 0.4493\n",
      "Epoch 8/12\n",
      "21060/21060 [==============================] - 9s 433us/step - loss: 1.5451 - acc: 0.4966 - val_loss: 1.9168 - val_acc: 0.4510\n",
      "Epoch 9/12\n",
      "21060/21060 [==============================] - 9s 437us/step - loss: 1.5290 - acc: 0.5019 - val_loss: 1.9073 - val_acc: 0.4529\n",
      "Epoch 10/12\n",
      "21060/21060 [==============================] - 9s 433us/step - loss: 1.5115 - acc: 0.5028 - val_loss: 1.9061 - val_acc: 0.4553\n",
      "Epoch 11/12\n",
      "21060/21060 [==============================] - 9s 433us/step - loss: 1.4966 - acc: 0.5052 - val_loss: 1.8629 - val_acc: 0.4247\n",
      "Epoch 12/12\n",
      "21060/21060 [==============================] - 9s 435us/step - loss: 1.4801 - acc: 0.5110 - val_loss: 1.8771 - val_acc: 0.4909\n",
      "Test loss: 1.8770589576497196\n",
      "Test accuracy: 0.49086595484511847\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 모델 정의 및 학습=====================================================================================\n",
    "#\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save('../keraslocationpredict.h5')\n",
    "#\n",
    "# ==================================================================================================\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
